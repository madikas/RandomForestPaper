---
title: "Random Forest Variable Importance and Variable Selection"
authors: "Madi Kassymbekov; Abderezzak Amimer; Sahar Nouri"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
source("RandomForest.R")
```

## Abstract

## Introduction

## Variable Importance

## Variable Selection

## Testing Methodology
To test out all different R packages that implement variable importance and variable selection methods, credit default dataset composed by Professor J.F.Plante for Statistical Learning class will be used as a sample dataset. For testing purposes, the original dataset was undersampled from 1 million rows to 10000 rows while maintaining only complete rows with preserving the original ratio of target binary variable that defines whether the client is going to default or not. This dataset will help to benchmark various R packages and find similarities and difference between their respective methods on random forest's variable importance and variable selection. The structure of the dataset is as following:


## R packages tutorials

## randomForest R package
**randomForest** R package is the main package that implements random forest decision tree model in R. This R package is not only able to fit a random forest model, but also has built-in functions to derive variable importance for the fitted model such as *importance* and *varImpPlot*. While these functions will show variable importance, it is also vital to tune random forest hyper-parameters such as *mtry* and *ntrees* to get relevant and optimal variable importance for the optimal model. For this purpose, *tuneRF* function performs hyper-parameter search. The parameters of *tuneRF* are as following.

| Parameter     | Description                                           |          
|---------------|:-----------------------------------------------------:|  
| x             | Data frame of predictors                              |  
| y             | Response label vector                                 |   
| mtryStart     | Starting number for mtry                              |  
| ntreeTry      | Number of trees per tuning step                       |  
| stepFactor    | multiplier for mtry parameter for next iteration      |  
| improve       | minimum OOB error improvement to continue search      |  
| plot          | plot the mtry to OOB error graph                      |  
| trace         | output error and mtry per each iteration              |  
| doBest        | run Random Forest fit based on best mtry              |  
For the test dataset, the following hyper-parameters were used. As a result, the optimal value for mtry is 4.
```{r, echo=TRUE, warnings=FALSE}
tuneRF(train_set[,2:29],train_set[,30], stepFactor = 1.5,
       plot=TRUE, trace=TRUE, doBest=FALSE)
```
*importance* function 

*varImpPlot* function shows the plot of all variables used in RandomForest model fit and their respective importance on MSE % increase, from which the statistician can derive each variable's importance on random forest model fit.
```{r, echo=FALSE, warnings=FALSE}
varImpPlot
```

## Conclusion

## References
